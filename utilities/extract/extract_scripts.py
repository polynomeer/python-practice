import whisper

# pip install openai-whisper
# pip install ffmpeg-python
# 1. Whisper ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (base/medium ì¶”ì²œ, tinyëŠ” ì •í™•ë„ ë‚®ìŒ)
model = whisper.load_model("medium")  # ë˜ëŠ” "base", "small"

# 2. ë³€í™˜í•  m4a ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
audio_path = "src.m4a"  # í˜„ì¬ í´ë”ì— ìœ„ì¹˜í•  ê²ƒ

# 3. ìŒì„± ì¸ì‹ ì‹¤í–‰ (language="ko"ë¡œ ëª…ì‹œ)
result = model.transcribe(audio_path, language="ko")

# 4. ê²°ê³¼ ì¶œë ¥
print("ğŸ”Š extracted scripts:")
print(result["text"])

# 5. ê²°ê³¼ë¥¼ txt íŒŒì¼ë¡œ ì €ì¥
output_path = "transcription.txt"
with open(output_path, "w", encoding="utf-8") as f:
    f.write(result["text"])

print(f"\nâœ… Extracted scripts save to '{output_path}'")
